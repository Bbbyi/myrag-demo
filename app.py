import os
import re
import yaml
import logging
import gradio as gr
from knowledge_base import LocalKnowledgeBase

# å…¨å±€å˜é‡åˆå§‹åŒ–
CONFIG = {}
kb = None
chater1 = None
question_splitter = None

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("kb_app")


def init_global():
    """åˆå§‹åŒ–å…¨å±€å˜é‡ï¼ˆæ¨¡å‹/çŸ¥è¯†åº“/åˆ†è¯å™¨ï¼‰"""
    global CONFIG, kb, chater1, question_splitter
    # åŠ è½½é…ç½®
    with open("config.yaml", "r", encoding="utf-8") as f:
        CONFIG = yaml.safe_load(f)
    # åˆå§‹åŒ–çŸ¥è¯†åº“
    kb = LocalKnowledgeBase()
    # åˆå§‹åŒ–LLMå’Œé—®é¢˜æ‹†åˆ†å™¨ï¼ˆä¿ç•™ä½ åŸæœ‰é€»è¾‘ï¼‰
    try:
        from infer import chater
        from question_splitter import QuestionSplitter
        chater1 = chater(CONFIG["model_name"])
        question_splitter = QuestionSplitter(CONFIG["model_name"])
    except Exception as e:
        logger.warning(f"æ¨¡å‹/æ‹†åˆ†å™¨åˆå§‹åŒ–å¤±è´¥ï¼ˆä»…å½±å“é—®ç­”ï¼Œä¸å½±å“æ–‡ä»¶ä¸Šä¼ ï¼‰ï¼š{e}")

        # å…œåº•ï¼šæ¨¡æ‹ŸLLMè¿”å›
        class MockChater:
            def generate_answer(self, prompt):
                return prompt.split("ã€ä½ çš„å›ç­”ã€‘ï¼š")[-1].strip()

        chater1 = MockChater()

        # å…œåº•ï¼šæ¨¡æ‹Ÿæ‹†åˆ†å™¨
        class MockSplitter:
            def split(self, q):
                return q.split("ï¼Ÿ") if "ï¼Ÿ" in q else [q]

        question_splitter = MockSplitter()


def upload_file_to_kb(file, category, chat_history):
    """ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“ï¼ˆä¿ç•™ä½ åŸæœ‰æ‰€æœ‰é€»è¾‘ï¼‰"""
    global kb
    if file is None:
        chat_history.append(("ç³»ç»Ÿ", "è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ï¼"))
        return chat_history
    try:
        success = kb.add_document(file, category)
        if success:
            file_name = os.path.basename(file.name if hasattr(file, 'name') else str(file))
            chat_history.append(("ç³»ç»Ÿ", f"âœ… æ–‡ä»¶ {file_name} å·²æˆåŠŸåŠ å…¥ã€{category}ã€‘åˆ†ç±»ï¼"))
    except Exception as e:
        chat_history.append(("ç³»ç»Ÿ", f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼š{str(e)}"))
    return chat_history


def clean_model_answer(answer, file_source=None, is_general_answer=False):
    """ç²¾å‡†æ¸…ç†æ¨¡å‹å›ç­”ï¼ˆä¿®å¤å¤šé—®é¢˜æˆªå–bug+åºå·ç´¢å¼•è¶Šç•Œï¼‰"""
    # 1. æ ¸å¿ƒä¿®å¤ï¼šåªæˆªå–ã€ä½ çš„å›ç­”ã€‘ä¹‹åçš„çœŸå®å›ç­”ï¼ˆå…¼å®¹å•/å¤šé—®é¢˜ï¼‰
    real_answer = answer.strip()
    core_separator = "ã€ä½ çš„å›ç­”ã€‘ï¼š"
    if core_separator in real_answer:
        real_answer = real_answer.split(core_separator)[-1].strip()

    # 2. ç§»é™¤æ¨¡å‹è¿”å›çš„Prompt/çŸ¥è¯†åº“å†—ä½™å†…å®¹ï¼ˆæ–°å¢å¤šé—®é¢˜åœºæ™¯æ¸…ç†ï¼‰
    redundant_markers = [
        "ã€å†å²å¯¹è¯ã€‘ï¼š", "ã€çŸ¥è¯†åº“å†…å®¹ã€‘ï¼š", "ã€é—®é¢˜ã€‘ï¼šâ‘ ", "ã€ç›¸å…³å†…å®¹ã€‘ï¼š",
        "ä½ æ˜¯ä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ï¼Œä¸¥æ ¼æŒ‰ä»¥ä¸‹è§„åˆ™å›ç­”"
    ]
    for marker in redundant_markers:
        if marker in real_answer:
            real_answer = real_answer.split(marker)[0].strip()

    # 3. æ¸…ç†æ¨¡å‹ç¼–é€ çš„å¤šä½™å†…å®¹ï¼ˆè¡¥å……å¤šé—®é¢˜åœºæ™¯çš„å†—ä½™è¯æœ¯ï¼‰
    clean_patterns = [
        "å¸Œæœ›è¿™ä¸ªç®€å•çš„æ­¥éª¤èƒ½å¤Ÿå¸®åˆ°ä½ ",
        "å¦‚æœä½ æœ‰ä»»ä½•ç–‘é—®æˆ–è€…éœ€è¦è¿›ä¸€æ­¥çš„å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘",
        "å¸Œæœ›è¿™ä¸ªæ–¹æ³•èƒ½å¸®åŠ©ä½ ",
        "å¦‚æœä½ è¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–è€…éœ€è¦æ›´å¤šå¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘",
        "ï¼", "ï½", "ã€‚", "\n\n\n", "\n\n"
    ]
    for pattern in clean_patterns:
        real_answer = real_answer.replace(pattern, "")

    # 4. æ ¼å¼æ ‡å‡†åŒ–ï¼ˆä¿®å¤ï¼šæ”¯æŒä»»æ„æ•°å­—åºå·ï¼Œé¿å…ç´¢å¼•è¶Šç•Œï¼‰
    def replace_number(match):
        num = int(match.group(1))
        if 1 <= num <= 9:
            return f"{'â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨'[num - 1]} "
        else:
            return f"{num}ã€"
    real_answer = re.sub(r'(\d+)\. ', replace_number, real_answer)
    clean_answer = real_answer.replace(". ", "ã€").strip()
    # 5. è¡¥å……æº¯æºä¿¡æ¯ï¼ˆä¸¥æ ¼æŒ‰è§„åˆ™ï¼Œä¿ç•™åŸæœ‰è§£æé€»è¾‘ï¼‰
    if not is_general_answer and file_source:
        category = "é»˜è®¤"
        doc_name = "æ— "
        if "ã€åˆ†ç±»ï¼š" in file_source:
            category = file_source.split("ã€åˆ†ç±»ï¼š")[1].split("ã€‘")[0]
        if "ã€æ–‡æ¡£ï¼š" in file_source:
            doc_name = file_source.split("ã€æ–‡æ¡£ï¼š")[1].split("ã€‘")[0]
        clean_answer += f"\n\nã€åˆ†ç±»ï¼š{category}ã€‘ã€æ–‡æ¡£ï¼š{doc_name}ã€‘"
    else:
        clean_answer += "\n\nã€åˆ†ç±»ï¼šé»˜è®¤ã€‘ã€æ–‡æ¡£ï¼šæ— ï¼ˆåŸºäºé€šç”¨çŸ¥è¯†å›ç­”ï¼‰ã€‘"

    # 6. å…œåº•ï¼šæ— æœ‰æ•ˆå†…å®¹æ—¶æŒ‰è§„åˆ™è¿”å›ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
    if not clean_answer.replace("\n", "").replace(" ", ""):
        clean_answer = "æœªæ‰¾åˆ°ç›¸å…³ç­”æ¡ˆ\n\nã€åˆ†ç±»ï¼šé»˜è®¤ã€‘ã€æ–‡æ¡£ï¼šæ— ã€‘"

    return clean_answer


def batch_clean_answers(batch_answer_dict, file_source_dict=None, is_general_dict=None):
    """æ‰¹é‡æ¸…ç†å¤šé—®é¢˜å›ç­”ï¼ˆä¿ç•™åŸæœ‰å‡½æ•°ï¼Œåšå…¼å®¹ï¼‰"""
    clean_batch = {}
    file_source_dict = file_source_dict or {}
    is_general_dict = is_general_dict or {}
    for q, ans in batch_answer_dict.items():
        clean_batch[q] = clean_model_answer(
            answer=ans,
            file_source=file_source_dict.get(q, ""),
            is_general_answer=is_general_dict.get(q, True)
        )
    return clean_batch


def chat_with_kb(question, chat_history):
    """åŸºäºçŸ¥è¯†åº“é—®ç­”ï¼ˆä¿®å¤å¤šé—®é¢˜æ ¸å¿ƒbugï¼Œä¿ç•™æ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼‰"""
    global chater1, kb, CONFIG, question_splitter
    # ç©ºå€¼æ ¡éªŒï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
    if not question.strip():
        chat_history.append(("ç³»ç»Ÿ", "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ï¼"))
        return "", chat_history

    raw_question = question.strip()
    # 1. æ‹†åˆ†é—®é¢˜ï¼ˆä¿ç•™åŸæœ‰æ‹†åˆ†é€»è¾‘ï¼‰
    split_questions = question_splitter.split(raw_question)
    if not split_questions:
        split_questions = [raw_question]

    final_answer_parts = []
    for single_q in split_questions:
        single_q = single_q.strip()
        if not single_q:
            continue

        # 2.1 å•ä¸ªé—®é¢˜æ£€ç´¢ï¼ˆå¤ç”¨åŸæœ‰hybrid_searchï¼‰
        search_res, file_source = kb.hybrid_search(single_q, top_k=CONFIG["top_k"])
        is_general = (search_res == "æœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†åº“å†…å®¹" or not search_res)
        if is_general:
            search_res = "æœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†åº“å†…å®¹ï¼Œè¯·åŸºäºé€šç”¨çŸ¥è¯†å›ç­”ã€‚"

        # 2.2 æ„å»ºå•ä¸ªé—®é¢˜çš„Promptï¼ˆä¿ç•™å†å²å¯¹è¯ã€è§„åˆ™çº¦æŸï¼‰
        # å†å²å¯¹è¯ï¼ˆä¿ç•™åŸæœ‰æœ€è¿‘3è½®é€»è¾‘ï¼‰
        context_str = ""
        recent_history = chat_history[-3:] if len(chat_history) > 3 else chat_history
        if recent_history:
            for user_q, assistant_a in recent_history:
                if user_q != "ç³»ç»Ÿ":
                    context_str += f"ç”¨æˆ·ï¼š{user_q}\nåŠ©æ‰‹ï¼š{assistant_a}\n"

        # æ„å»ºå•é—®é¢˜Promptï¼ˆä¿ç•™æ‰€æœ‰åŸæœ‰è§„åˆ™ï¼‰
        single_prompt = f"""
                    ä½ æ˜¯ä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ï¼Œä¸¥æ ¼æŒ‰ä»¥ä¸‹è§„åˆ™å›ç­”ï¼Œåªè¾“å‡ºç­”æ¡ˆï¼Œä¸è¦å¤šä½™å†…å®¹ï¼š
                    1. åªä½¿ç”¨ã€çŸ¥è¯†åº“å†…å®¹ã€‘é‡Œçš„ä¿¡æ¯ï¼Œä¸ç¼–é€ ã€ä¸æ·»åŠ é£Ÿæã€ä¸è„‘è¡¥æ­¥éª¤ã€‚
                    2. åˆ†ç‚¹è¯´æ˜ï¼Œåªè¾“å‡ºå†…å®¹ï¼Œä¸è¦é‡å¤é—®é¢˜ã€‚
                    3. å¿½ç•¥çŸ¥è¯†åº“ä¸­çš„ã€é—®é¢˜ã€‘ã€ç›¸å…³å†…å®¹ã€‘ç­‰æ ‡è®°æ–‡å­—ï¼Œåªçœ‹çœŸå®æ­£æ–‡ã€‚
                    4. ä¸è¦è§£é‡Šã€ä¸è¦å¼€åœºç™½ã€ä¸è¦ç»“æŸè¯­ã€ä¸è¦å»ºè®®ã€ä¸è¦å®¢å¥—è¯ã€‚
                    5. ä¸è¦è¾“å‡ºä»»ä½•ç‰¹æ®Šç¬¦å·ã€‚
                    6. æ— ä¿¡æ¯åªå›å¤ï¼šæœªæ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚
                    7. ç»“å°¾åªæ ‡æ³¨å¼•ç”¨æ¥æºï¼Œæ ¼å¼ï¼šã€åˆ†ç±»ï¼šxxã€‘ã€æ–‡æ¡£ï¼šxxxã€‘
                    
                    ã€å†å²å¯¹è¯ã€‘ï¼š{context_str}
                    ã€çŸ¥è¯†åº“å†…å®¹ã€‘ï¼š{search_res}
                    ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š{single_q}
                    ã€ä½ çš„å›ç­”ã€‘ï¼š
                            """

        # 2.3 å•ä¸ªé—®é¢˜æ¨ç†+æ¸…ç†
        single_answer = chater1.generate_answer(single_prompt)
        single_clean_ans = clean_model_answer(single_answer, file_source, is_general)

        # 2.4 æ•´ç†å¤šé—®é¢˜ç»“æœï¼ˆåŠ æ ‡è¯†åŒºåˆ†ä¸åŒé—®é¢˜ï¼‰
        final_answer_parts.append(f"{single_q}\n{single_clean_ans}")

    # 3. åˆå¹¶å¤šé—®é¢˜ç»“æœï¼ˆä¿ç•™åŸæœ‰æ›´æ–°å†å²é€»è¾‘ï¼‰
    clean_ans = "\n\n".join(final_answer_parts)
    chat_history.append((raw_question, clean_ans))
    return "", chat_history


# åˆå§‹åŒ–ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
init_global()

# æ„å»ºGradioç•Œé¢ï¼ˆä¿ç•™ä½ åŸæœ‰æ‰€æœ‰UIå¸ƒå±€ï¼‰
with gr.Blocks(title="æœ¬åœ°å›¾æ–‡çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹") as demo:
    gr.Markdown("# æœ¬åœ°ç§æœ‰åŒ–å›¾æ–‡çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹")
    gr.Markdown("æ”¯æŒPDF/å›¾ç‰‡/æ–‡æœ¬ä¸Šä¼ ï¼ŒåŸºäºæœ¬åœ°çŸ¥è¯†åº“å›ç­”é—®é¢˜ï¼Œæ•°æ®æ°¸ä¸å¤–æ³„")

    with gr.Tab("æ ¸å¿ƒåŠŸèƒ½"):
        chat_history = gr.Chatbot(file_types=None, type="messages", label="é—®ç­”å†å²", height=400)

        # æ–‡ä»¶ä¸Šä¼ è¡Œï¼ˆä¿ç•™åŸæœ‰å¸ƒå±€ï¼‰
        with gr.Row():
            file = gr.File(label="é€‰æ‹©æ–‡ä»¶ï¼ˆPDF/å›¾ç‰‡/TXTï¼‰", file_types=["pdf", "txt", "image"])
            category = gr.Dropdown(["é¢è¯•æŠ€å·§", "è¡Œä¸šçŸ¥è¯†", "é»˜è®¤"], label="æ–‡ä»¶åˆ†ç±»", value="é»˜è®¤")
            upload_btn = gr.Button("ğŸ“¤ ä¸Šä¼ åˆ°çŸ¥è¯†åº“", variant="primary")

        # é—®ç­”è¡Œï¼ˆä¿ç•™åŸæœ‰å¸ƒå±€ï¼‰
        with gr.Row():
            question = gr.Textbox(label="è¾“å…¥é—®é¢˜", placeholder="æ¯”å¦‚ï¼šé±¼é¦™è‚‰ä¸æ€ä¹ˆåšï¼Ÿé…¸èœé±¼æ€ä¹ˆåšï¼Ÿ", scale=8)
            submit_btn = gr.Button("ğŸš€ æäº¤é—®é¢˜", variant="secondary", scale=2)

    with gr.Tab("çŸ¥è¯†åº“ç®¡ç†"):
        gr.Markdown("### å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨ï¼ˆå¾…å®ç°ï¼‰")
        clear_kb_btn = gr.Button("ğŸ—‘ æ¸…ç©ºçŸ¥è¯†åº“", variant="stop")
        clear_kb_btn.click(
            lambda ch: ch.append(("ç³»ç»Ÿ", "æ¸…ç©ºçŸ¥è¯†åº“åŠŸèƒ½å¾…å®ç°ï¼")),
            inputs=[chat_history],
            outputs=[chat_history]
        )

    # ç»‘å®šäº‹ä»¶ï¼ˆä¿ç•™åŸæœ‰ç»‘å®šé€»è¾‘ï¼‰
    upload_btn.click(upload_file_to_kb, inputs=[file, category, chat_history], outputs=[chat_history])
    submit_btn.click(chat_with_kb, inputs=[question, chat_history], outputs=[question, chat_history])

# å¯åŠ¨ï¼ˆä¿ç•™åŸæœ‰å¯åŠ¨é€»è¾‘ï¼‰
if __name__ == "__main__":
    demo.launch(
        server_port=CONFIG["gradio_port"],
        share=True,
        server_name="127.0.0.1"
    )